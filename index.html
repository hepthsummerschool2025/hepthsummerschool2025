<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="Artificial Intelligence For Theoretical Sciences">
<title>Artificial Intelligence For Theoretical Sciences</title>  

<link rel="stylesheet" href="kits.css"> 
	

</head>

<body>  

	<div class="container">
	<!-- Top box -->
		<!-- Logo & Site Name -->
		<div class="placeholder">
			<div class="parallax-window">
				<div class="tm-header">
					<div class="tm-header-inner">
						<div class="col-md-6 col-12">
							<img src="workshoplogo.png"  style="max-width: 100%;" /> 
								 <div class="tm-site-text-box"> 
							<!-- <h1 class="tm-site-title">Exact methods in quantum field theory and string theory</h1> -->
								
								<!-- <h1 class="tm-site-title">国科大卡弗里所-上科大暑期学校</h1>   -->
                                                           
							<!--	<h6 class="tm-site-description">2023年8月6日-18日，上海科技大学</h6>   -->	
							</div>
						</div>
						<nav class="col-md-6 col-12 tm-nav">
							<ul class="tm-nav-ul">
								<li class="tm-nav-li"><a href="index.html" class="tm-nav-link active"> About the workshop </a></li>
								<li class="tm-nav-li"><a href="#timeandvenue" class="tm-nav-link" >Time and venue</a></li>
								<li class="tm-nav-li"><a href="#spe" class="tm-nav-link" >Speakers</a></li>
								<li class="tm-nav-li"><a href="#sch" class="tm-nav-link" >Program</a></li>
		                                                
								<!-- <li class="tm-nav-li"><a href="#app" class="tm-nav-link" >申请</a></li>  -->	
								
								<li class="tm-nav-li"><a href="#org" class="tm-nav-link" >Organizers</a></li>
								<li class="tm-nav-li"><a href="#con" class="tm-nav-link" >Contact</a></li>
						
							</ul>
						</nav>	
					</div>
				</div>
			</div>
		</div>



<main>


	<h4 style="margin-top: 30pt;"> About the workshop </h4>

<p class="p2" style="margin-top:-10pt;">		
This workshop is organized by the Kavli Institute of Theoretical Sciences (KITS) of the University of Chinese Academy of Sciences and the Institute of Physics of the Chinese Academy of Sciences. It aims to provide i) a timely overview of the exploding field of AI for science with an emphasis on applications to the theoretical sciences; ii) a venue for researchers in AI for science to present and exchange ideas, and to identify future directions of disruptive research; and iii) an introduction for physicists to the plethora of cutting-edge ML techniques in the field of AI for science. 
<br>
The topics of the workshop include: 
<br>
<dl>
  <dt>AI for differential equations</dt>
  <dd>Physical laws are often expressed in terms of partial differential equations (PDEs), such as Maxwell’s equations in electrodynamics, the Navier-Stokes equations in fluid dynamics, and Schrodinger’s equation in quantum mechanics. Neural networks and neural operators provide a novel paradigm to solve such PDEs by exploiting the universal representational nature of deep neural networks in either a data-driven or a self-supervised manner. Their increased performance opens the door to previously infeasibly high resolutions and amortizes the often inhibitive computational cost of large-scale PDE solvers.</dd>
  <dt>AI for theoretical high energy physics</dt>
  <dd>Machine learning provides powerful tools to tackle a wide variety of problems in theoretical high-energy physics. For example, reinforcement learning techniques can be applied successfully in the numerical conformal bootstrap program; the search for a string vacuum that describes Nature, which effectively is a computational algebraic geometry question, may be rendered surmountable; and there exists a correspondence between neural networks and field theories which potentially opens the door to a non-perturbative definition of QFTs in the continuum. What’s more, intuition, ideas, and concepts from theoretical physics have proved, time and again, to facilitate and drive novel directions of research in machine learning, such as in the blossoming field of energy-based models.</dd>
  <dt>AI for quantum mechanics and quantum chemistry</dt>
  <dd>Open quantum systems are described by a density matrix whose dynamics can often be described by a master equation. As the (complex) dimension of the density matrix scales as N^k, where N is the dimension of the Hilbert space and k the number of subsystems, the time evolution of systems with many subsystems and/or (infinitely) large Hilbert spaces is exceedingly hard. Deep generative neural networks allow one to succinctly represent the density matrix, thus reducing the computational cost of modeling their temporal evolution. Similar techniques can be applied to continuous many-body wave functions in quantum chemistry.</dd>
  <dt>AI for lattice field theory</dt>
  <dd>Lattice field theories (on a finite lattice) are defined in terms of high-dimensional probability distributions. To compute physical observables, lattice field theorists need to be able to sample reliably and efficiently from said distributions. Traditionally, Markov Chain Monte Carlo methods are brought to bear for this task, but these are known to suffer from critical slowing down – the phenomenon that consecutively generated samples are increasingly correlated – when trying to probe a critical point or the continuum limit. Several machine learning models, including real non-volume preserving flows and continuous flows based on neural ordinary differential equations, that deal gracefully with probability distributions and admit convenient sampling provide compelling alternatives and are actively investigated.</dd>
  <dt>AI for inverse design in material science, biophysics, and engineering</dt>
  <dd>Inverse design aims to answer the question which design, among all possible designs, realizes a particular desired target property. It finds applications in many scientific and engineering fields, e.g., in material science it can be deployed for the design of materials for batteries or solar cells with improved performance and in biophysics it can be leveraged to engineer biomolecules (e.g., proteins) with specific functions and properties. At heart it is an optimization problem that greatly benefits from machine learning methodologies, be it via the use of physics-informed surrogate models, invertible deep learning models, or generative AI models.</dd>
</dl> 
	
<br>


<br>
	
	
<img src="AIforTheoreticalSciences_photo.jpg"  width="900" > 
	
<br>



<br>

<h4> <div id="timeandvenue">Time and venue</div> </h4>

	<p style="margin-top:-10pt;">

	The workshop will take place at Room M234 in Institute of Physics, Beijing from November 11 (registration day) till November 15, 2024.

	
<br>	
	
<h4> <div id="spe">Confirmed Invited speakers</div> </h4>

<p style="margin-top:-10pt;">
	

	
<ul>
	<li> Fanglin Bao (Westlake University): Are there physical limits on machine learning?  <a href="FanglinBAO_AILimits2share.pdf"> Slides </a>
	<li> Aurélien Decelle (Universidad Complutense Madrid): How phase transitions shape the learning of complex data in the Restricted Boltzmann Machine
	<li> Dong-Ling Deng (Tsinghua University): Quantum adversarial machine learning: from theory to experiment
	<li> Bin Dong (Peking University): AI for Mathematics：from Digitization to Intelligentization
	<li> Youngjoon Hong (KAIST): AI for Scientific Computing: Theory and Applications  <a href="UCAS_Hong.pdf"> Slides </a>
	<li> Gerhard Jung (Université Grenoble Alpes): Can Generative AI Models Efficiently Sample Deeply Supercooled Liquids? <a href="Gerhard_Jung.pdf"> Slides </a>
	<li> Miao Liu (IoP, CAS): A high-accuracy out-of-the-box universal AI force field for arbitrary inorganic materials <a href="Miao_Liu.pdf"> Slides </a>
	<li> Jannes Nys (École Polytechnique Fédérale de Lausanne): Machine learning fermionic matter: strongly correlated systems in and out of equilibrium
	<li> Weiluo Ren (ByteDance Research): Recent progress in neural network based quantum Monte Carlo  <a href="Weiluo_Ren.pdf"> Slides </a>
	<li> Rak-Kyeong Seong (Ulsan National Institute of Science and Technology): Machine Learning the Geometry of Quantum Fields and Strings
	<li> Tailin Wu (Westlake University): Compositional inverse design and closed-loop control of physical systems via diffusion generative models
	<li> Han Wang (Institute of Applied Physics and Computational Mathematics): Deep learning variational free energy for atomic systems
	<li> Yong Xu (Tsinghua University): Deep learning density functional theory and beyond
	<li> Marius Zeinhofer ((Freiburg University): First Optimize, Then Discretize for Scientific Machine Learning <a href="slides_marius.pdf"> Slides </a>
	<li> Pan Zhang (ITP, CAS): Decoding quantum error-correcting codes using generative models
	<li> Yi Zhang (Peking University): Machine Learning for Quantum Materials, Models, and Algorithms <a href="AITSworkshop_YiZhang20241113.pptx"> Slides </a>
	<li> Kai Zhou (CUHK-SZ): Extreme QCD matter Exploration Meets Machine Learning  <a href="Kai_Zhou.pdf"> Slides </a>
	</li>

	
	
	
	
	
	
	
	
	
	
	
	



 
 	
	
	








	
		

		
</p>

		
		
		
<br>

<h4> <div id="sch"> Program </div> </h4>
	
<br>

<p class="p2" style="margin-top:-10pt;">

	

	
		
<br>
		
<br>

	
<img src="schedule.png"  width="900" > 

	</ul>
</p>
	
	
<br>
	
</ul>
</p>

<br>

<!-- <h4> <div id="app">申请 (Applying to the summer school)</div> </h4> -->
	
<!-- <br> -->

<!-- <p class="p2" style="margin-top:-10pt;"> -->

	
<br>
<h4> <div id="org"> Organizers </div> </h4>

<br>

<p class="p2" style="margin-top:-10pt;">

Wolfger Peelaers (HPE labs) <br>
Lei Wang (Institute of Physics, Chinese Academy of Sciences) <br>
Long Zhang (Kavli ITS, University of Chinese Academy of Sciences) <br>
Xinan Zhou (Kavli ITS, University of Chinese Academy of Sciences) <br>
	
<br>




</p>


<br>	
<h4> <div id="con">Contact </div> </h4>
	
<p class="p2" style="margin-top:-10pt;">
	
<br>

Please email any questions you may have to the organizers: xinan.zhou@ucas.ac.cn <br>


</p>



	


<br>


	


</main>



</body>
</html>
